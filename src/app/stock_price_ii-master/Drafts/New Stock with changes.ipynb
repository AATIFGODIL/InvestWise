{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a9959-2bc2-4e46-b9f0-e6718836a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.ensemble import GradientBoostingRegressor  \n",
    "from sklearn.neighbors import KNeighborsRegressor  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.metrics import r2_score  \n",
    "from yahoofinancials import YahooFinancials  \n",
    "from datetime import datetime, timedelta  \n",
    "from tensorflow.keras import layers  \n",
    "from tensorflow.keras import losses  \n",
    "from tensorflow.keras import Model  \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import GradientTape\n",
    "\n",
    "  \n",
    "class PortfolioForecastService:  \n",
    "    def __init__(self):  \n",
    "        #self.yahoo_financials = YahooFinancials()\n",
    "        self.end_date = None\n",
    "        self.start_date = None\n",
    "        self.historical_data = None\n",
    "        \n",
    "    def update(self, yahoo):\n",
    "        self.end_date = datetime.now().strftime('%Y-%m-%d')  \n",
    "        self.start_date = (datetime.now() - timedelta(days=5*365)).strftime('%Y-%m-%d')  \n",
    "        self.historical_data = yahoo.get_historical_price_data(self.start_date, self.end_date, 'monthly')\n",
    "  \n",
    "    def get_historical_data(self,  symbol):  \n",
    "        #end_date = datetime.now().strftime('%Y-%m-%d')  \n",
    "        #start_date = (datetime.now() - timedelta(days=5*365)).strftime('%Y-%m-%d')  \n",
    "        #historical_data = self.yahoo_financials.get_historical_price_data(start_date, end_date, 'monthly')[symbol]['prices']\n",
    "        return pd.DataFrame(self.historical_data[symbol]['prices']) \n",
    "  \n",
    "    def get_forecast_data(self, symbol, historical_data):  \n",
    "        # Extract latent representations using the VAE  \n",
    "        vae = self.VAE(historical_data)  \n",
    "        latent_representations = vae.predict(historical_data)   \n",
    "        # Generate synthetic stock price data using GAN  \n",
    "        gan = self.GAN(latent_representations)  \n",
    "        synthetic_data = gan.predict(np.random.rand(historical_data.shape[0],10))\n",
    "          \n",
    "        # Combine Latent Representations and Synthetic Data  \n",
    "        enriched_data = np.concatenate((latent_representations, synthetic_data), axis=1)  \n",
    "          \n",
    "        X = enriched_data  \n",
    "        y = historical_data['close']\n",
    "        print(X.shape, y.shape)\n",
    "  \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
    "  \n",
    "        scaler = StandardScaler()  \n",
    "        X_train_scaled = scaler.fit_transform(X_train)  \n",
    "        X_test_scaled = scaler.transform(X_test)  \n",
    "  \n",
    "        regressor = GradientBoostingRegressor()  \n",
    "        regressor.fit(X_train_scaled, y_train)  \n",
    "        y_pred = regressor.predict(X_test_scaled)  \n",
    "  \n",
    "        score = r2_score(y_test, y_pred)  \n",
    "  \n",
    "        return y_pred, score  \n",
    "  \n",
    "    def get_portfolio_forecast(self, portfolio):\n",
    "        forecast_data = {}  \n",
    "        accuracy_scores = {}\n",
    "        yahoo = YahooFinancials(portfolio)\n",
    "        self.update(yahoo)\n",
    "        for symbol in portfolio:  \n",
    "            historical_data = self.get_historical_data(symbol).drop(\"formatted_date\", axis = 'columns')\n",
    "            forecast, score = self.get_forecast_data(symbol, historical_data)  \n",
    "            forecast_data[symbol] = forecast  \n",
    "            accuracy_scores[symbol] = score  \n",
    "        return forecast_data, accuracy_scores  \n",
    "  \n",
    "    def VAE(self, data):  \n",
    "        latent_dim = 64   \n",
    "  \n",
    "        class Encoder(Model):  \n",
    "          def __init__(self, latent_dim):  \n",
    "            super(Encoder, self).__init__()  \n",
    "            self.latent_dim = latent_dim  \n",
    "            self.encoder = layers.Dense(latent_dim, activation='relu')  \n",
    "  \n",
    "          def call(self, x):  \n",
    "            encoded = self.encoder(x)  \n",
    "            return encoded  \n",
    "  \n",
    "        class Decoder(Model):  \n",
    "          def __init__(self, original_dim):  \n",
    "            super(Decoder, self).__init__()  \n",
    "            self.decoder = layers.Dense(original_dim, activation='sigmoid')  \n",
    "  \n",
    "          def call(self, x):  \n",
    "            decoded = self.decoder(x)  \n",
    "            return decoded  \n",
    "  \n",
    "        class VAE(Model):  \n",
    "          def __init__(self, encoder, decoder):  \n",
    "            super(VAE, self).__init__()  \n",
    "            self.encoder = encoder  \n",
    "            self.decoder = decoder  \n",
    "  \n",
    "          def call(self, x):  \n",
    "            encoded = self.encoder(x)  \n",
    "            decoded = self.decoder(encoded)  \n",
    "            return decoded  \n",
    "  \n",
    "        encoder = Encoder(latent_dim)  \n",
    "        decoder = Decoder(data.shape[1])  \n",
    "        vae = VAE(encoder, decoder)  \n",
    "  \n",
    "        vae.compile(optimizer=optimizers.Adam(), loss=losses.MeanSquaredError())  \n",
    "        vae.fit(data, data, epochs=10, batch_size=32)  \n",
    "  \n",
    "        return vae  \n",
    "  \n",
    "    def GAN(self, data):  \n",
    "        #latent_dim = 64   \n",
    "        epochs = 3\n",
    "        class Generator(Model):  \n",
    "          def __init__(self, latent_dim=0):  \n",
    "            super(Generator, self).__init__()  \n",
    "            self.generator = layers.Dense(data.shape[-1], activation='relu')  \n",
    "  \n",
    "          def call(self, x):  \n",
    "            generated = self.generator(x)  \n",
    "            return generated  \n",
    "  \n",
    "        class Discriminator(Model):  \n",
    "          def __init__(self):  \n",
    "            super(Discriminator, self).__init__()  \n",
    "            self.discriminator = layers.Dense(1)  \n",
    "  \n",
    "          def call(self, x):  \n",
    "            validity = self.discriminator(x)  \n",
    "            return validity\n",
    "        \n",
    "        def genloss(x):\n",
    "            return losses.MSE(x,np.zeros(x.shape))\n",
    "        def discloss(f,r):\n",
    "            real  = losses.MSE(f,np.ones(f.shape))\n",
    "            fake = losses.MSE(r,np.zeros(r.shape))\n",
    "            return real+fake\n",
    "        generator = Generator()\n",
    "        discriminator = Discriminator()\n",
    "        randomdata = np.random.rand(data.shape[0],10)\n",
    "        goptimizer = optimizers.legacy.Adam()\n",
    "        doptimizer = optimizers.legacy.Adam()\n",
    "        for i in range(epochs):\n",
    "            with GradientTape() as gtape, GradientTape() as dtape:\n",
    "                faker = generator(randomdata)\n",
    "                ruler = discriminator(faker)\n",
    "                realer = discriminator(data)\n",
    "                gloss = genloss(ruler)\n",
    "                dloss = discloss(ruler,realer)\n",
    "                ggradient = gtape.gradient(gloss,generator.trainable_variables)\n",
    "                dgradient = dtape.gradient(dloss,discriminator.trainable_variables)\n",
    "            goptimizer.apply_gradients(zip(ggradient,generator.trainable_variables))\n",
    "            doptimizer.apply_gradients(zip(dgradient,discriminator.trainable_variables))\n",
    "        return generator                \n",
    "            \n",
    "          \n",
    "          \n",
    "  \n",
    "          \n",
    "\"\"\"\n",
    "        class GAN(Model):  \n",
    "          def __init__(self, generator, discriminator):  \n",
    "            super(GAN, self).__init__()  \n",
    "            self.generator = generator  \n",
    "            self.discriminator = discriminator  \n",
    "  \n",
    "          def call(self, x):  \n",
    "            generated = self.generator(x)  \n",
    "            validity = self.discriminator(generated)  \n",
    "            return validity  \n",
    "        generator = Generator(latent_dim)  \n",
    "        discriminator = Discriminator()  \n",
    "        gan = GAN(generator, discriminator)\n",
    "        gan.compile(optimizer=optimizers.Adam(), loss=losses.BinaryCrossentropy(from_logits=True))  \n",
    "        gan.fit(data, np.ones((data.shape[0], 1)), epochs=10, batch_size=32)\n",
    "\"\"\"\n",
    "            \n",
    "\n",
    "x = PortfolioForecastService()\n",
    "print(x.get_portfolio_forecast([\"XOM\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
